{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AntiOxiPred_LSE_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shujaat123/AntiOxiLSE/blob/main/AntiOxiPred_LSE_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeEJa2_TZnec"
      },
      "source": [
        "## **AntiOxi-LSE: Prediction of Antioxidant Proteins Using Latent Space Encoding of Composition of k-Spaced Amino Acid Pairs**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-m_byicZkQc"
      },
      "source": [
        "This code provide python implementation of AntiOxi-LSE algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LadaflfshqgF"
      },
      "source": [
        "# Loading Useful packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si6012nzZktl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876c9fe4-b54d-44a1-9bba-560df695de79"
      },
      "source": [
        "## Load useful packages\n",
        "import sys, os, re, gc\n",
        "from scipy.io import savemat\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras import optimizers\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, BatchNormalization, Dropout\n",
        "from keras import optimizers\n",
        "from keras import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report, accuracy_score, matthews_corrcoef, balanced_accuracy_score, precision_recall_fscore_support\n",
        "from sklearn.metrics import auc, average_precision_score, precision_recall_curve, roc_curve\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from random import sample\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEwrowDzZ_Ah"
      },
      "source": [
        "# Feature-Extraction\n",
        "\n",
        "The CKSAAP feature encoding calculates the frequency of amino acid pairs separated by any k residues. The CKSAAP encoding scheme reflects the amino acid pair information in small and large range with in the peptides depending upon the value of k(gap). The encoding scheme is utilized from iFeature web server, using the following download link: (https://github.com/Superzchen/iFeature).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p258z8dGR0iQ"
      },
      "source": [
        "## Define CKSAAP feature-extraction function\n",
        "def Convert_Seq2CKSAAP(train_seq, gap=8):\n",
        "  cksaapfea = []\n",
        "  seq_label = []\n",
        "  for sseq in train_seq:\n",
        "    temp= CKSAAP([sseq], gap=8)\n",
        "    cksaapfea.append(temp[1][1:])\n",
        "    seq_label.append(sseq[0])\n",
        "\n",
        "  x = np.array(cksaapfea)\n",
        "  y = np.array(seq_label)\n",
        "  y[y=='POS']=1\n",
        "  y[y=='NEG']=0\n",
        "  y = to_categorical(y)\n",
        "\n",
        "  return x,y\n",
        "\n",
        "def minSequenceLength(fastas):\n",
        "\tminLen = 10000\n",
        "\tfor i in fastas:\n",
        "\t\tif minLen > len(i[1]):\n",
        "\t\t\tminLen = len(i[1])\n",
        "\treturn minLen\n",
        "\n",
        "def CKSAAP(fastas, gap=5, **kw):\n",
        "\tif gap < 0:\n",
        "\t\tprint('Error: the gap should be equal or greater than zero' + '\\n\\n')\n",
        "\t\treturn 0\n",
        "\n",
        "\tif minSequenceLength(fastas) < gap+2:\n",
        "\t\tprint('Error: all the sequence length should be larger than the (gap value) + 2 = ' + str(gap+2) + '\\n' + 'Current sequence length ='  + str(minSequenceLength(fastas)) + '\\n\\n')\n",
        "\t\treturn 0\n",
        "\n",
        "\tAA = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\tencodings = []\n",
        "\taaPairs = []\n",
        "\tfor aa1 in AA:\n",
        "\t\tfor aa2 in AA:\n",
        "\t\t\taaPairs.append(aa1 + aa2)\n",
        "\theader = ['#']\n",
        "\tfor g in range(gap+1):\n",
        "\t\tfor aa in aaPairs:\n",
        "\t\t\theader.append(aa + '.gap' + str(g))\n",
        "\tencodings.append(header)\n",
        "\tfor i in fastas:\n",
        "\t\tname, sequence = i[0], i[1]\n",
        "\t\tcode = [name]\n",
        "\t\tfor g in range(gap+1):\n",
        "\t\t\tmyDict = {}\n",
        "\t\t\tfor pair in aaPairs:\n",
        "\t\t\t\tmyDict[pair] = 0\n",
        "\t\t\tsum = 0\n",
        "\t\t\tfor index1 in range(len(sequence)):\n",
        "\t\t\t\tindex2 = index1 + g + 1\n",
        "\t\t\t\tif index1 < len(sequence) and index2 < len(sequence) and sequence[index1] in AA and sequence[index2] in AA:\n",
        "\t\t\t\t\tmyDict[sequence[index1] + sequence[index2]] = myDict[sequence[index1] + sequence[index2]] + 1\n",
        "\t\t\t\t\tsum = sum + 1\n",
        "\t\t\tfor pair in aaPairs:\n",
        "\t\t\t\tcode.append(myDict[pair] / sum)\n",
        "\t\tencodings.append(code)\n",
        "\treturn encodings\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlxQRVJ87u3A"
      },
      "source": [
        "def load_seq_data(data_path):\n",
        "  dataset = pd.read_csv(data_path,names=None,index_col=0, header=None)\n",
        "  seq = []\n",
        "  POS_sample_count = 0\n",
        "  NEG_sample_count = 0\n",
        "  for row in dataset.iterrows():\n",
        "    if(row[0].startswith('ind_pos')):\n",
        "      POS_sample_count = POS_sample_count +1\n",
        "      label = 'POS'\n",
        "      array = [label, np.asarray(row[1])[0]]\n",
        "      name, sequence = array[0].split()[0], re.sub('[^ARNDCQEGHILKMFPSTWYV-]', '-', ''.join(array[1:]).upper())\n",
        "      seq.append([name, sequence])\n",
        "    \n",
        "    elif(row[0].startswith('all_neg')):\n",
        "      NEG_sample_count = NEG_sample_count +1\n",
        "      label = 'NEG'\n",
        "      array = [label, np.asarray(row[1])[0]]\n",
        "      name, sequence = array[0].split()[0], re.sub('[^ARNDCQEGHILKMFPSTWYV-]', '-', ''.join(array[1:]).upper())\n",
        "      seq.append([name, sequence])\n",
        "\n",
        "    elif(row[0].startswith('>anti_')):\n",
        "      POS_sample_count = POS_sample_count +1\n",
        "      label = 'POS'\n",
        "      continue  \n",
        "    elif(row[0].startswith('>nonanti_')):\n",
        "      NEG_sample_count = NEG_sample_count +1\n",
        "      label = 'NEG'\n",
        "      continue\n",
        "    else:\n",
        "      array = [label, row[0]]\n",
        "      name, sequence = array[0].split()[0], re.sub('[^ARNDCQEGHILKMFPSTWYV-]', '-', ''.join(array[1:]).upper())\n",
        "      seq.append([name, sequence])\n",
        "  print('# of POS samples',POS_sample_count,'\\t # of NEG samples',NEG_sample_count)\n",
        "  return seq"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNyCMw_QK6Bg"
      },
      "source": [
        "## Loading and pre-processing protein's dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyMD3sDDxN74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f485d8e-f553-43d2-8e6d-dbefb75c504a"
      },
      "source": [
        "# ## Loading and pre-processing PVP prediction dataset\n",
        "pos_seq_path = 'https://raw.githubusercontent.com/Shujaat123/AntiOxiLSE/main/AodPred/anti.txt'\n",
        "neg_seq_path = 'https://raw.githubusercontent.com/Shujaat123/AntiOxiLSE/main/AodPred/nonanti.txt'\n",
        "ind_seq_path = 'https://raw.githubusercontent.com/Shujaat123/AntiOxiLSE/main/Independent_TestDataset_Antioxidant.txt'\n",
        "pos_all_seq = load_seq_data(pos_seq_path)\n",
        "neg_all_seq = load_seq_data(neg_seq_path)\n",
        "ind_all_seq = load_seq_data(ind_seq_path)\n",
        "ALL_seq = pos_all_seq + neg_all_seq\n",
        "\n",
        "print(len(pos_all_seq), len(neg_all_seq), len(ALL_seq), len(ind_all_seq))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of POS samples 253 \t # of NEG samples 0\n",
            "# of POS samples 0 \t # of NEG samples 1552\n",
            "# of POS samples 22 \t # of NEG samples 0\n",
            "253 1552 1805 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ar9mtHsEaAyA"
      },
      "source": [
        "# Designing an Auto-Encoder-based classifier model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge7uF0idR-Gc"
      },
      "source": [
        "## Designing an Auto-Encoder-Classifier model\n",
        "def LSE_Final_Model(input_shape=3600, LV=5,num_Neurons=5):\n",
        "    # Encoder Network\n",
        "    enc_input = Input(shape=(input_shape,), name='enc_input')\n",
        "    enc_l1 = Dense(num_Neurons*10, activation='relu', name='encoder_layer1')(enc_input)\n",
        "    enc_l1 = BatchNormalization()(enc_l1)\n",
        "    enc_l1 = Dropout(rate = 0.3)(enc_l1)\n",
        "\n",
        "    enc_l2 = Dense(num_Neurons*5, activation='relu', name='encoder_layer2')(enc_l1)\n",
        "    enc_l2 = BatchNormalization()(enc_l2)\n",
        "    enc_l2 = Dropout(rate = 0.3)(enc_l2)\n",
        "\n",
        "    enc_l3 = Dense(num_Neurons*2, activation='relu', name='encoder_layer3')(enc_l2)\n",
        "    enc_l3 = BatchNormalization()(enc_l3)\n",
        "    enc_l3 = Dropout(rate = 0.3)(enc_l3)\n",
        "\n",
        "    encoder_output = Dense(LV, activation='sigmoid', name='encoder_output')(enc_l3)\n",
        "  \n",
        "    # Classifier Network\n",
        "    class_l1 = Dense(num_Neurons*2, activation='relu', name='class_layer1')(encoder_output)\n",
        "    class_l2 = Dense(num_Neurons*2, activation='relu', name='class_layer3')(class_l1)\n",
        "    class_output = Dense(2, activation='softmax', name='class_output')(class_l2)\n",
        "\n",
        "    # Decoder Network\n",
        "    dec_l1 = Dense(num_Neurons*2, activation='relu', name='decoder_layer1')(encoder_output)\n",
        "    dec_l1 = BatchNormalization()(dec_l1)\n",
        "    dec_l1 = Dropout(rate = 0.3)(dec_l1)\n",
        "\n",
        "    dec_l2 = Dense(num_Neurons*5, activation='relu', name='decoder_layer2')(dec_l1)\n",
        "    dec_l2 = BatchNormalization()(dec_l2)\n",
        "    dec_l2 = Dropout(rate = 0.3)(dec_l2)\n",
        "\n",
        "    dec_l3 = Dense(num_Neurons*10, activation='relu', name='decoder_layer3')(dec_l2)\n",
        "    dec_l3 = BatchNormalization()(dec_l3)\n",
        "    dec_l3 = Dropout(rate = 0.3)(dec_l3)\n",
        "\n",
        "    decoder_output = Dense(input_shape, activation='sigmoid', name='decoder_output')(dec_l3)\n",
        "\n",
        "    model = Model(inputs=[enc_input], outputs=[class_output, decoder_output])\n",
        "\n",
        "    # Compiling model\n",
        "    model.compile(optimizer='rmsprop',\n",
        "                  loss={'class_output': 'binary_crossentropy', 'decoder_output': 'mean_squared_error'},\n",
        "                  loss_weights={'class_output': 0.01, 'decoder_output': 0.99},\n",
        "                  metrics=[metrics.categorical_accuracy])\n",
        "    # Here I used rmsprops optimizer with default values, two objective functions are optimized\n",
        "    # using  weight factors [1 for classifier and 0.1 for decoder loss]\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83mfGGGKaBdj"
      },
      "source": [
        "## Define performance measures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsirQcmlTK7y"
      },
      "source": [
        "## Define performance measures\n",
        "def yoden_index(y, y_pred):\n",
        "  tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "  j = (tp/(tp+fn)) + (tn/(tn+fp)) - 1\n",
        "  return j\n",
        "\n",
        "def pmeasure(y, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y, y_pred, labels=[0,1]).ravel()\n",
        "    sensitivity = tp / (tp + fn )\n",
        "    specificity = tn / (tn + fp)\n",
        "    f1score = (2 * tp) / (2 * tp + fp + fn)\n",
        "    return ({'Sensitivity': sensitivity, 'Specificity': specificity, 'F1-Score': f1score})\n",
        "\n",
        "def Show_Statistics(msg,Stats):\n",
        "  print(msg.upper())\n",
        "  print(70*'-')\n",
        "  print('Accuracy:',Stats[0])\n",
        "  print('Sensitivity:',Stats[1])\n",
        "  print('Specificity:',Stats[2])\n",
        "  print('F1-Score:',Stats[3])\n",
        "  print('MCC:',Stats[4])\n",
        "  print('Balance Accuracy:',Stats[5])\n",
        "  print('Youden-Index:',Stats[6])\n",
        "  print('AUC:',Stats[7])\n",
        "  print('AUPR:',Stats[8])\n",
        "  print('Reconstruction MSE:',Stats[9])\n",
        "  print(70*'-')\n",
        "\n",
        "def Calculate_Stats(y_actual,y_pred, y_score):\n",
        "  acc = accuracy_score(y_actual.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "  sen = pmeasure(y_actual.argmax(axis=1), y_pred.argmax(axis=1))['Sensitivity']\n",
        "  spe = pmeasure(y_actual.argmax(axis=1), y_pred.argmax(axis=1))['Specificity']\n",
        "  f1 = pmeasure(y_actual.argmax(axis=1), y_pred.argmax(axis=1))['F1-Score']\n",
        "  mcc = matthews_corrcoef(y_actual.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "  bacc = balanced_accuracy_score(y_actual.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "  yi = yoden_index(y_actual.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "  #auc = roc_auc_score(y_actual.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "  \n",
        "  pre, rec, _ = precision_recall_curve(y_actual.argmax(axis=1), y_score, pos_label=1)\n",
        "  fpr, tpr, _ = roc_curve(y_actual.argmax(axis=1), y_score, pos_label=1)\n",
        "  auroc = auc(fpr, tpr)\n",
        "  aupr = auc(rec, pre)\n",
        "    \n",
        "  return acc, sen, spe, f1, mcc, bacc, yi, auroc, aupr  \n",
        "\n",
        "def label_by_th(y_pred, threshold=0.5):\n",
        "  y_pred_copy = y_pred.copy()\n",
        "  y_pred_copy[y_pred>= threshold] = 1 \n",
        "  y_pred_copy[y_pred<threshold] = 0 \n",
        "  return y_pred_copy\n",
        "\n",
        "def cutoff_youdens_j(fpr,tpr,thresholds):\n",
        "  j_scores = tpr-fpr\n",
        "  j_ordered = sorted(zip(j_scores,thresholds))\n",
        "  return j_ordered[-1][1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooB2PHJbaD16"
      },
      "source": [
        "  ## Perform Monte-Carlos Simulations for [num_Trials]\\# of independent Trials\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW4-Y7y-Q28O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82bf0cb6-74f8-49fe-bb62-009f6ee53740"
      },
      "source": [
        "  ## Perform Monte-Carlos Simulations for [num_Trials]# of independent Trials\n",
        "LVs = range(6,7)\n",
        "num_Trails = 10\n",
        "gaps = range(6,7)\n",
        "num_Neurons = 5\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "for gap_ind in range(0,len(gaps)):\n",
        "    [DataX, LabelY] = Convert_Seq2CKSAAP(ALL_seq, gap=gaps[gap_ind])\n",
        "    [IndX, IndY] = Convert_Seq2CKSAAP(ind_all_seq, gap=gaps[gap_ind])\n",
        "    plist = list(np.asarray(np.where(LabelY[:,1]==1)).flatten())\n",
        "    nlist = list(np.asarray(np.where(LabelY[:,1]==0)).flatten())\n",
        "    total_list = plist + nlist\n",
        "\n",
        "    for lv_ind in range(0,len(LVs)):\n",
        "      Stats =[]\n",
        "      for loop_ind in range(0,num_Trails):\n",
        "        ## train\n",
        "        p_train = sample(plist, 200) # out of 253\n",
        "        n_train = sample(nlist, 1240) # out of 1552\n",
        "        train_list = p_train + n_train\n",
        "        X_train = DataX[list(train_list)]\n",
        "        y_train = LabelY[list(train_list)]\n",
        "\n",
        "        ## test\n",
        "        test_list = set(total_list) - (set(train_list))\n",
        "        X_test = DataX[list(test_list)]\n",
        "        y_test = LabelY[list(test_list)]\n",
        "        \n",
        "        model = LSE_Final_Model(input_shape = X_train.shape[1],LV=LVs[lv_ind],num_Neurons=num_Neurons)\n",
        "        es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=100)\n",
        "        checkpoint = ModelCheckpoint('models\\\\model-best.h5',\n",
        "                                    verbose=0, monitor='val_loss',save_best_only=True, mode='auto')\n",
        "        history = model.fit({'enc_input': X_train},\n",
        "                          {'class_output': y_train, 'decoder_output': X_train},\n",
        "                          validation_data = ({'enc_input': X_test},\n",
        "                          {'class_output': y_test, 'decoder_output': X_test}),\n",
        "                          epochs=1000, batch_size=y_train.shape[0], callbacks=[checkpoint, es], verbose=0)\n",
        "        del model  # deletes the existing model\n",
        "        model = load_model('models\\\\model-best.h5')\n",
        "\n",
        "        y_train_pred, X_train_pred = model.predict(X_train,batch_size=1800, verbose=0)\n",
        "        y_train_score = y_train_pred[:,1]\n",
        "        # y_train_pred = to_categorical(y_train_pred.argmax(axis=1))\n",
        "        MSE_X_train_pred = (np.square(X_train_pred - X_train)).mean(axis=1)\n",
        "\n",
        "        y_test_pred, X_test_pred = model.predict(X_test,batch_size=200, verbose=0)\n",
        "        y_test_score = y_test_pred[:,1]\n",
        "        \n",
        "        # Optimal Threshold\n",
        "        fpr, tpr, thresholds_AUC = roc_curve(y_test.argmax(axis=1), y_test_score)\n",
        "        precision, recall, thresholds_AUPR = precision_recall_curve(y_test.argmax(axis=1),y_test_score)\n",
        "\n",
        "        ## Optimal Threshold metrics\n",
        "        distance = (1-fpr)**2+(1-tpr)**2\n",
        "        EERs = (1-recall)/(1-precision)\n",
        "        positive = sum(y_test.argmax(axis=1))\n",
        "        negative = y_test.shape[0]-positive\n",
        "        ratio = negative/positive\n",
        "        opt_t_AUC = thresholds_AUC[np.argmin(distance)]\n",
        "        opt_t_AUPR = thresholds_AUPR[np.argmin(np.abs(EERs-ratio))]\n",
        "        opt_yodens_j = cutoff_youdens_j(fpr, tpr, thresholds_AUC)        \n",
        "        y_test_pred_th = label_by_th(y_test_score, opt_yodens_j)\n",
        "        y_test_pred = to_categorical(y_test_pred_th)\n",
        "        MSE_X_test_pred = (np.square(X_test_pred - X_test)).mean(axis=1)\n",
        "\n",
        "        # re-scaled training pred label\n",
        "        y_train_pred_th = label_by_th(y_train_score, opt_yodens_j)\n",
        "        y_train_pred = to_categorical(y_train_pred_th)\n",
        "\n",
        "        print(confusion_matrix(y_test.argmax(axis=1), y_test_pred.argmax(axis=1), labels=[0,1]).ravel())\n",
        "\n",
        "        ## Training Measures\n",
        "        tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi, tr_auc, tr_aupr = Calculate_Stats(y_train,y_train_pred, y_train_score);\n",
        "        \n",
        "        ## Test Measures\n",
        "        t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi, t_auc, t_aupr = Calculate_Stats(y_test,y_test_pred, y_test_score);\n",
        "\n",
        "        ## Independent Measures\n",
        "        y_ind_pred, X_ind_pred = model.predict(IndX,batch_size=200, verbose=0)\n",
        "        y_ind_score = y_ind_pred[:,1]\n",
        "        y_ind_pred_th = label_by_th(y_ind_score, opt_yodens_j)\n",
        "        y_ind_pred = to_categorical(y_ind_pred_th)\n",
        "        MSE_X_ind_pred = (np.square(X_ind_pred - IndX)).mean(axis=1)\n",
        "        ind_acc, ind_sen, ind_spe, ind_f1, ind_mcc, ind_bacc, ind_yi, ind_auc, ind_aupr = Calculate_Stats(IndY,y_ind_pred, y_ind_score);\n",
        "\n",
        "        Stats.append([tr_acc, tr_sen, tr_spe, tr_f1, tr_mcc, tr_bacc, tr_yi, tr_auc, tr_aupr, -10*np.log10(MSE_X_train_pred.mean()),\n",
        "                      t_acc, t_sen, t_spe, t_f1, t_mcc, t_bacc, t_yi, t_auc, t_aupr,-10*np.log10(MSE_X_test_pred.mean())])\n",
        "        print('CKSAAP-Gap:',gaps[gap_ind], 'LV=',LVs[lv_ind],'Trial:',loop_ind,\n",
        "              ' \\nTraining/ Test Youden-index:', tr_yi,'/',t_yi,\n",
        "              ' \\nTraining/ Test MCC:', tr_mcc,'/',t_mcc,\n",
        "              ' \\nTraining/ Test AUC:', tr_auc,'/',t_auc,\n",
        "              ' \\nTraining/ Test AUPR:', tr_aupr,'/',t_aupr,\n",
        "              ' \\nTraining/ Test MSE (dB):', -10*np.log10(MSE_X_train_pred.mean()), '/', -10*np.log10(MSE_X_test_pred.mean()))\n",
        "        print(y_ind_pred.argmax(axis=1)==IndY.argmax(axis=1))\n",
        "        print('Independent Dataset Accuracy:', ind_acc)\n",
        "      \n",
        "      del model  # deletes the existing model\n",
        "      Statistics = np.asarray(Stats)\n",
        "      filename = 'AntiOxi_LSE_STATS_CKSAAP_GAP' + str(gaps[gap_ind]) + '_LV' + str(LVs[lv_ind]) + '.mat'\n",
        "      savemat(filename,{'Statistics':Statistics})\n",
        "      print('SAVING... '+ filename)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: RuntimeWarning: divide by zero encountered in true_divide\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
            "  warnings.warn('y_pred contains classes not in y_true')\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:800: UndefinedMetricWarning: No negative samples in y_true, false positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[290  22  16  37]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 0  \n",
            "Training/ Test Youden-index: 0.983709677419355 / 0.6276003870343492  \n",
            "Training/ Test MCC: 0.9582541332747667 / 0.6006364934149486  \n",
            "Training/ Test AUC: 0.9997419354838709 / 0.8528664731494922  \n",
            "Training/ Test AUPR: 0.9986074476916738 / 0.6859758759975328  \n",
            "Training/ Test MSE (dB): 42.78470521345468 / 42.87106216260234\n",
            "[ True False  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 0.9090909090909091\n",
            "[270  42  17  36]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 1  \n",
            "Training/ Test Youden-index: 0.8343548387096775 / 0.5446298984034832  \n",
            "Training/ Test MCC: 0.6694953789058885 / 0.46808902769244043  \n",
            "Training/ Test AUC: 0.9572701612903225 / 0.8075108853410741  \n",
            "Training/ Test AUPR: 0.6927225975655869 / 0.488878368895874  \n",
            "Training/ Test MSE (dB): 35.99654386038785 / 36.03441996854209\n",
            "[ True  True False  True  True  True  True  True  True  True  True False\n",
            "  True  True  True  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 0.9090909090909091\n",
            "[266  46  11  42]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 2  \n",
            "Training/ Test Youden-index: 0.9212903225806452 / 0.6450169327527817  \n",
            "Training/ Test MCC: 0.809452406377133 / 0.5312575644644241  \n",
            "Training/ Test AUC: 0.992375 / 0.8696178035800678  \n",
            "Training/ Test AUPR: 0.9526619753372412 / 0.6714444860526009  \n",
            "Training/ Test MSE (dB): 33.51697208203121 / 33.587343675334495\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 1.0\n",
            "[181 131   5  48]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 3  \n",
            "Training/ Test Youden-index: 0.7270967741935483 / 0.48578858248669565  \n",
            "Training/ Test MCC: 0.5226424463017384 / 0.3423572644466035  \n",
            "Training/ Test AUC: 0.9725322580645162 / 0.830188679245283  \n",
            "Training/ Test AUPR: 0.7724048970329542 / 0.45461788221517574  \n",
            "Training/ Test MSE (dB): 44.43754160541517 / 44.30906552147479\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 1.0\n",
            "[217  95  14  39]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 4  \n",
            "Training/ Test Youden-index: 0.5653225806451614 / 0.4313618771165939  \n",
            "Training/ Test MCC: 0.40116987677126825 / 0.31528158348399005  \n",
            "Training/ Test AUC: 0.8487620967741936 / 0.7513909046927915  \n",
            "Training/ Test AUPR: 0.3703572739892929 / 0.30658065008823543  \n",
            "Training/ Test MSE (dB): 34.94819744555721 / 34.96489792046637\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True False  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 0.9545454545454546\n",
            "[245  67  14  39]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 5  \n",
            "Training/ Test Youden-index: 0.8217741935483871 / 0.5211054668601838  \n",
            "Training/ Test MCC: 0.6421282024734595 / 0.4044250487006761  \n",
            "Training/ Test AUC: 0.9784758064516128 / 0.8129535558780842  \n",
            "Training/ Test AUPR: 0.8973746729154972 / 0.47441659336124664  \n",
            "Training/ Test MSE (dB): 38.49709300489072 / 38.49284169310848\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 1.0\n",
            "[291  21  17  36]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 6  \n",
            "Training/ Test Youden-index: 0.9950000000000001 / 0.6119375907111757  \n",
            "Training/ Test MCC: 0.9970948937970248 / 0.5938948756184467  \n",
            "Training/ Test AUC: 1.0 / 0.8544992743105951  \n",
            "Training/ Test AUPR: 1.0 / 0.6815671040855257  \n",
            "Training/ Test MSE (dB): 44.7172595041631 / 45.116410915990535\n",
            "[ True False False  True  True  True  True  True  True False  True False\n",
            "  True  True  True  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 0.8181818181818182\n",
            "[213  99   9  44]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 7  \n",
            "Training/ Test Youden-index: 0.9256451612903227 / 0.5128809869375908  \n",
            "Training/ Test MCC: 0.8034464821266565 / 0.37015815808775543  \n",
            "Training/ Test AUC: 0.9964758064516129 / 0.8266811804547654  \n",
            "Training/ Test AUPR: 0.9959050062314291 / 0.593841123886066  \n",
            "Training/ Test MSE (dB): 40.29062763456061 / 40.317939290583965\n",
            "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 1.0\n",
            "[289  23  21  32]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 8  \n",
            "Training/ Test Youden-index: 0.8975806451612902 / 0.5300556361877118  \n",
            "Training/ Test MCC: 0.8644092989504247 / 0.5220048005523741  \n",
            "Training/ Test AUC: 0.9910362903225807 / 0.8499637155297532  \n",
            "Training/ Test AUPR: 0.9691010506929837 / 0.625518381979969  \n",
            "Training/ Test MSE (dB): 38.42813592770433 / 38.39458331667909\n",
            "[ True False  True  True  True  True False  True  True False  True  True\n",
            "  True  True  True  True  True  True  True  True  True False]\n",
            "Independent Dataset Accuracy: 0.8181818181818182\n",
            "[242  70  13  40]\n",
            "CKSAAP-Gap: 6 LV= 6 Trial: 9  \n",
            "Training/ Test Youden-index: 0.8754838709677419 / 0.5303580067731013  \n",
            "Training/ Test MCC: 0.7129157161644855 / 0.40720952572303076  \n",
            "Training/ Test AUC: 0.9897782258064516 / 0.8183357522980165  \n",
            "Training/ Test AUPR: 0.9479318034692316 / 0.5419018448575709  \n",
            "Training/ Test MSE (dB): 40.55862271864327 / 40.747224862818065\n",
            "[ True False  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True]\n",
            "Independent Dataset Accuracy: 0.9090909090909091\n",
            "SAVING... AntiOxi_LSE_STATS_CKSAAP_GAP6_LV6.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddwzm0NGaFsy"
      },
      "source": [
        "## Show Classification/Reconstruction Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSXF9ZkXXv3Y"
      },
      "source": [
        "## Show Classification/Reconstruction Statistics\n",
        "Show_Statistics('Training Results (MEAN)',Statistics.mean(axis=0)[0:10])\n",
        "Show_Statistics('Test Results (MEAN)',Statistics.mean(axis=0)[10:20])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}